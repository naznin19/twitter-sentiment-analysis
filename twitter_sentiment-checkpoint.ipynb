{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"twitter_dataset/train_tweets.csv\")\n",
    "\n",
    "X_tweet = data1[\"tweet\"]\n",
    "y =  data1[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    #print(r)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt\n",
    "\n",
    "data1['trimmed_tweet'] = np.vectorize(remove_pattern)(X_tweet, \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          when a father is dysfunctional and is so sel...\n",
      "1          thanks for #lyft credit i can't use cause th...\n",
      "2                                      bihday your majesty\n",
      "3        #model   i love u take with u all the time in ...\n",
      "4                   factsguide: society now    #motivation\n",
      "5        [2/2] huge fan fare and big talking before the...\n",
      "6                         camping tomorrow        dannyâ¦\n",
      "7        the next school year is the year for exams.ð...\n",
      "8        we won!!! love the land!!! #allin #cavs #champ...\n",
      "9                    welcome here !  i'm   it's so #gr8 ! \n",
      "10        â #ireland consumer price index (mom) climb...\n",
      "11       we are so selfish. #orlando #standwithorlando ...\n",
      "12       i get to see my daddy today!!   #80days #getti...\n",
      "13        #cnn calls #michigan middle school 'build the...\n",
      "14       no comment!  in #australia   #opkillingbay #se...\n",
      "15       ouch...junior is angryð#got7 #junior #yugyo...\n",
      "16       i am thankful for having a paner. #thankful #p...\n",
      "17                                  retweet if you agree! \n",
      "18       its #friday! ð smiles all around via ig use...\n",
      "19       as we all know, essential oils are not made of...\n",
      "20       #euro2016 people blaming ha for conceded goal ...\n",
      "21       sad little dude..   #badday #coneofshame #cats...\n",
      "22       product of the day: happy man #wine tool  who'...\n",
      "23                     lumpy says i am a . prove it lumpy.\n",
      "24         #tgif   #ff to my #gamedev #indiedev #indieg...\n",
      "25       beautiful sign by vendor 80 for $45.00!! #upsi...\n",
      "26         all #smiles when #media is   !! ðð #pr...\n",
      "27       we had a great panel on the mediatization of t...\n",
      "28                  happy father's day  ðððð  \n",
      "29       50 people went to nightclub to have a good nig...\n",
      "                               ...                        \n",
      "31932                                       thanks gemma  \n",
      "31933     judd is a  &amp; #homophobic #freemilo #milo ...\n",
      "31934    lady banned from kentucky mall.   #jcpenny #ke...\n",
      "31935    ugh i'm trying to enjoy my happy hour drink &a...\n",
      "31936    want to know how to live a   life? do more thi...\n",
      "31937                                   love island ð  \n",
      "31938    my fav actor #vijaysethupathi ! my fav actress...\n",
      "31939        whew  ð",
      " it's a productive and   #friday!!!\n",
      "31940                              she's finally here!    \n",
      "31941    passed first year of uni #yay #love #pass #uni...\n",
      "31942    this week is flying by   #humpday - #wednesday...\n",
      "31943      modeling photoshoot this friday yay #model #...\n",
      "31944    you're surrounded by people who love you (even...\n",
      "31945    feel like... ðð¶ð #dog #summer #hot #h...\n",
      "31946     omfg i'm offended! i'm a  mailbox and i'm pro...\n",
      "31947      you don't have the balls to hashtag me as a ...\n",
      "31948     makes you ask yourself, who am i? then am i a...\n",
      "31949    hear one of my new songs! don't go - katie ell...\n",
      "31950      you can try to 'tail' us to stop, 'butt' we'...\n",
      "31951    i've just posted a new blog: #secondlife #lone...\n",
      "31952                             you went too far with   \n",
      "31953    good morning #instagram #shower #water #berlin...\n",
      "31954    #holiday   bull up: you will dominate your bul...\n",
      "31955    less than 2 weeks ð",
      "ðð¼ð¹ððµ  #i...\n",
      "31956    off fishing tomorrow  carnt wait first time in...\n",
      "31957    ate  isz that youuu?ððððððð...\n",
      "31958      to see nina turner on the airwaves trying to...\n",
      "31959    listening to sad songs on a monday morning otw...\n",
      "31960     #sikh #temple vandalised in in #calgary, #wso...\n",
      "31961                          thank you  for you follow  \n",
      "Name: trimmed_tweet, Length: 31962, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X = data1['trimmed_tweet']\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 1,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'class_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6412e2be2645>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4370\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4371\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4372\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4374\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'class_count'"
     ]
    }
   ],
   "source": [
    "y.class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 154)\t1\n",
      "  (0, 2475)\t1\n",
      "  (0, 5502)\t1\n",
      "  (0, 6820)\t1\n",
      "  (0, 8989)\t1\n",
      "  (0, 11470)\t1\n",
      "  (0, 11839)\t1\n",
      "  (1, 309)\t2\n",
      "  (1, 390)\t1\n",
      "  (1, 940)\t1\n",
      "  (1, 4326)\t1\n",
      "  (1, 6289)\t1\n",
      "  (2, 1365)\t2\n",
      "  (2, 3390)\t1\n",
      "  (2, 3595)\t1\n",
      "  (2, 8921)\t1\n",
      "  (3, 4057)\t2\n",
      "  (3, 6106)\t1\n",
      "  (3, 9333)\t1\n",
      "  (3, 12559)\t2\n",
      "  (4, 3646)\t1\n",
      "  (5, 1266)\t1\n",
      "  (5, 2388)\t1\n",
      "  (5, 2804)\t1\n",
      "  (5, 4909)\t1\n",
      "  :\t:\n",
      "  (6390, 7436)\t1\n",
      "  (6390, 9231)\t1\n",
      "  (6390, 9825)\t1\n",
      "  (6390, 9911)\t1\n",
      "  (6390, 10342)\t1\n",
      "  (6390, 12277)\t1\n",
      "  (6391, 648)\t1\n",
      "  (6391, 6735)\t1\n",
      "  (6391, 7454)\t1\n",
      "  (6391, 8157)\t1\n",
      "  (6391, 10516)\t1\n",
      "  (6391, 12470)\t1\n",
      "  (6392, 1645)\t1\n",
      "  (6392, 2914)\t1\n",
      "  (6392, 3025)\t1\n",
      "  (6392, 4449)\t1\n",
      "  (6392, 5154)\t1\n",
      "  (6392, 5218)\t1\n",
      "  (6392, 5302)\t1\n",
      "  (6392, 6060)\t1\n",
      "  (6392, 7089)\t1\n",
      "  (6392, 7332)\t1\n",
      "  (6392, 10045)\t1\n",
      "  (6392, 10437)\t1\n",
      "  (6392, 11750)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words =\"english\",min_df=2)\n",
    "vect.fit(X_train,y_train)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "print(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9535429375879868\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm,y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "accuracy =metrics.accuracy_score(y_test,y_pred_class)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5821  139]\n",
      " [ 158  275]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9742013099852961\n",
      "0.9781237417796269\n"
     ]
    }
   ],
   "source": [
    "#calculating precission and recall,\n",
    "# when it predicts a text is straight, it is correct 97 % of the time.\n",
    "# it correctly identifies 97% of all straight speech.\n",
    "precission = float(7288/(7288+193))\n",
    "print(precission)\n",
    "recall = float(7288/(7288+163))\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5960\n",
       "1     433\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27798    #sick   &amp;   over alleged #tigeemple #slaug...\n",
       "7233       a  #repoer  tries to understand #twitter tri...\n",
       "8919     jo cox attack is a sign for all politicians to...\n",
       "195      what a self-serving hypocrite! always keep you...\n",
       "26749    so you seek to shame someone  to stop  as the ...\n",
       "8976       these actions will insure a dem potus or 3rd...\n",
       "10111                             retweet if you're  ! xo \n",
       "21772    looks like #prayforoakland tag is full f libta...\n",
       "22427    watching asians in leicester on tv using same ...\n",
       "20265    what a massive disappointment  is. suppoing a ...\n",
       "Name: trimmed_tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 10 false positve when actually is straight but predict as hate\n",
    "X_test[y_test < y_pred_class].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_token = vect.get_feature_names()\n",
    "straight_speech = nb.feature_count_[0,:]\n",
    "hate_speech = nb.feature_count_[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   straight_speech  hate_speech\n",
      "0             36.0          0.0\n",
      "1             19.0          2.0\n",
      "2              2.0          0.0\n",
      "3              6.0          0.0\n",
      "4              3.0          0.0\n",
      "5              2.0          0.0\n",
      "6              8.0          0.0\n"
     ]
    }
   ],
   "source": [
    "tokens = pd.DataFrame({'straight_speech':straight_speech, 'hate_speech':hate_speech})\n",
    "print(tokens.head(7))\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23760.,  1809.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count the number of each class\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"twitter_dataset/test_tweets.csv\")\n",
    "data_2 = test_data[\"tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\estia\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X['trimmed_tweet_test'] = np.vectorize(remove_pattern)(data_2, \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = X[\"trimmed_tweet_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "test_dtm = vect.transform(test_data)\n",
    "test_predict_class = nb.predict(test_dtm)\n",
    "print(test_predict_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9597997810104802\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.fit(X_train_dtm,y_train)\n",
    "logit_pred_class = logit.predict(X_test_dtm)\n",
    "accuracy =metrics.accuracy_score(y_test,logit_pred_class)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Grid Search to find the best model and the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'alpha': [0.1,0.01, 1]}]\n",
    "grid_search = GridSearchCV(estimator = nb,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = grid_search.fit(X_train_dtm, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952794399468106\n",
      "{'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(best_accuracy)\n",
    "print(best_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "text =[\"লবণাক্ততার কারণে উদ্বাস্তু হবে মানুষ\"]\n",
    "test_dtm = vect.transform(text)\n",
    "predict_class = nb.predict(test_dtm)\n",
    "print(predict_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
